# MARLTCD



## Repository Status

This repository provides the core resources for reproducing the key findings of our paper:

- **Core TCD Implementation**: The primary algorithm and model code.
- **Experimental Configurations**: Hyperparameter settings and network architecture details.
- **Supporting Data**: Additional experimental data referenced in the manuscript.

> **Note:** We are actively enhancing this repository to improve its usability. This includes adding comprehensive documentation, refactoring auxiliary scripts, and ensuring full reproducibility. Updates will be integrated progressively.

Please refer to the associated publication for full context, and feel free to **open an issue** for any immediate questions.

## 1 TCD Implementation



## 2 Experimental Configurations



## 3 Supporting Data



## Thanks

Portions of the code in this repository are built upon and significantly inspired by the following pioneering works. We express our sincere gratitude to the authors (all references are formally cited in the paper):

- The StarCraft Multi-Agent Challenge (SMAC) benchmark and baseline implementations:  
  M. Samvelyan et al., "The StarCraft Multi-Agent Challenge," AAMAS 2019. 

- The Google Research Football environment:  
  K. Kurach et al., "Google Research Football: A Novel Reinforcement Learning Environment," AAAI 2020.
